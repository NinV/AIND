{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "# Load training set\n",
    "X_train, y_train = load_data()\n",
    "print(\"X_train.shape == {}\".format(X_train.shape))\n",
    "print(\"y_train.shape == {}; y_train.min == {:.3f}; y_train.max == {:.3f}\".format(\n",
    "    y_train.shape, y_train.min(), y_train.max()))\n",
    "\n",
    "# Load testing set\n",
    "X_test, _ = load_data(test=True)\n",
    "print(\"X_test.shape == {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import deep learning resources from Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Specify a CNN architecture\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Convolution2D(16, (3,3), strides=(2, 2), padding='same', activation='relu', input_shape = X_train.shape[1:]))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(Convolution2D(32, (3,3), strides=(2, 2), padding='same', activation='relu'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(Convolution2D(64, (3,3), strides=(2, 2), padding='same', activation='relu'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(Convolution2D(128, (3,3), strides=(2, 2), padding='same', activation='relu'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(GlobalAveragePooling2D())\n",
    "model_1.add(Dense(256, activation='relu'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(Dense(y_train.shape[1], ))\n",
    "\n",
    "# Summarize the model\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "## TODO: Compile the model\n",
    "batch_size = 16\n",
    "epochs = 60\n",
    "\n",
    "model_1.compile(Adam(), 'mean_squared_error', metrics = ['mse'])\n",
    "checkpointer = ModelCheckpoint(filepath = \"saved_models/model_selection/model_1.h5\", verbose = 0, save_best_only = True)\n",
    "hist = model_1.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2, callbacks = [checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Visualize the training and validation loss of your neural network\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "print(val_loss)\n",
    "model_loss_fig = plt.figure(figsize = (10,10))\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title(\"model 1\")\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Replace GAP layer by flatten layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Specify a CNN architecture\n",
    "\n",
    "model_2 = Sequential()\n",
    "model_2.add(Convolution2D(16, (3,3), strides=(2, 2), padding='same', activation='relu', input_shape = X_train.shape[1:]))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Convolution2D(32, (3,3), strides=(2, 2), padding='same', activation='relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Convolution2D(64, (3,3), strides=(2, 2), padding='same', activation='relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Convolution2D(128, (3,3), strides=(2, 2), padding='same', activation='relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dense(256, activation='relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Dense(y_train.shape[1], ))\n",
    "\n",
    "# Summarize the model\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TODO: Compile the model\n",
    "batch_size = 16\n",
    "epochs = 60\n",
    "\n",
    "model_2.compile(Adam(), 'mean_squared_error', metrics = ['mse'])\n",
    "checkpointer = ModelCheckpoint(filepath = \"saved_models/model_selection/model_2.h5\", verbose = 0, save_best_only = True)\n",
    "hist = model_2.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2, callbacks = [checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TODO: Visualize the training and validation loss of your neural network\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "print(val_loss)\n",
    "model_loss_fig = plt.figure(figsize = (10,10))\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title(\"model 2\")\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: Using multiple Maxpooling layers instead of 2x2 strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## TODO: Specify a CNN architecture\n",
    "\n",
    "model_3 = Sequential()\n",
    "model_3.add(Convolution2D(16, (3,3), strides=(1, 1), padding='same', activation='relu', input_shape = X_train.shape[1:]))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(MaxPooling2D())\n",
    "model_3.add(Convolution2D(32, (3,3), strides=(1, 1), padding='same', activation='relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(MaxPooling2D())\n",
    "model_3.add(Convolution2D(64, (3,3), strides=(1, 1), padding='same', activation='relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(MaxPooling2D())\n",
    "model_3.add(Convolution2D(128, (3,3), strides=(1, 1), padding='same', activation='relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(MaxPooling2D())\n",
    "model_3.add(Flatten())\n",
    "model_3.add(Dense(256, activation='relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Dense(y_train.shape[1], ))\n",
    "\n",
    "# Summarize the model\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "## TODO: Compile the model\n",
    "batch_size = 16\n",
    "epochs = 60\n",
    "\n",
    "model_3.compile(Adam(), 'mean_squared_error', metrics = ['mse'])\n",
    "checkpointer = ModelCheckpoint(filepath = \"saved_models/model_selection/model_3.h5\", verbose = 0, save_best_only = True)\n",
    "hist = model_3.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2, callbacks = [checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TODO: Visualize the training and validation loss of your neural network\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "print(val_loss)\n",
    "model_loss_fig = plt.figure(figsize = (10,10))\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title(\"model 3\")\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4: Increase number of CONV layers and using 2x2 stride instead of Maxpooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## TODO: Specify a CNN architecture\n",
    "\n",
    "model_4 = Sequential()\n",
    "model_4.add(Convolution2D(16, (3,3), strides=(1, 1), padding='same', activation='relu', input_shape = X_train.shape[1:]))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(Convolution2D(16, (3,3), strides=(2, 2), padding='same', activation='relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(Convolution2D(32, (3,3), strides=(1, 1), padding='same', activation='relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(Convolution2D(32, (3,3), strides=(2, 2), padding='same', activation='relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(Convolution2D(64, (3,3), strides=(1, 1), padding='same', activation='relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(Convolution2D(64, (3,3), strides=(2, 2), padding='same', activation='relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(Convolution2D(128, (3,3), strides=(1, 1), padding='same', activation='relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(Convolution2D(128, (3,3), strides=(2, 2), padding='same', activation='relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(Flatten())\n",
    "model_4.add(Dense(256, activation='relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(Dense(y_train.shape[1], ))\n",
    "\n",
    "# Summarize the model\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "## TODO: Compile the model\n",
    "batch_size = 16\n",
    "epochs = 60\n",
    "\n",
    "model_4.compile(Adam(), 'mean_squared_error', metrics = ['mse'])\n",
    "checkpointer = ModelCheckpoint(filepath = \"saved_models/model_selection/model_4.h5\", verbose = 0, save_best_only = True)\n",
    "hist = model_4.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2, callbacks = [checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TODO: Visualize the training and validation loss of your neural network\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "print(val_loss)\n",
    "model_loss_fig = plt.figure(figsize = (10,10))\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title(\"model 4\")\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
