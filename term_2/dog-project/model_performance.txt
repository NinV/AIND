Model 1:

model = Sequential()

### TODO: Define your architecture.
model.add(Conv2D(16, 10, strides=(2,2), padding='valid', activation='relu', input_shape=train_tensors.shape[1:]))
model.add(Conv2D(32, 3, strides=(2,2), padding='same', activation='relu'))
model.add(Conv2D(64, 3, strides=(2,2), padding='same', activation='relu'))
model.add(Conv2D(128, 3, strides=(1,1), padding='same', activation='relu'))
model.add(GlobalAveragePooling2D())
model.add(Dense(train_targets.shape[1], activation='softmax'))
model.summary()

Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 108, 108, 16)      4816      
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 54, 54, 32)        4640      
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 27, 27, 64)        18496     
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 27, 27, 128)       73856     
_________________________________________________________________
global_average_pooling2d_1 ( (None, 128)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 133)               17157     
=================================================================
Total params: 118,965
Trainable params: 118,965
Non-trainable params: 0

Train on 6680 samples, validate on 835 samples
Epoch 1/20
6660/6680 [============================>.] - ETA: 0s - loss: 4.8870 - acc: 0.0075Epoch 00000: val_loss improved from inf to 4.87000, saving model to saved_models/weights.best.from_scratch.hdf5
6680/6680 [==============================] - 135s - loss: 4.8869 - acc: 0.0076 - val_loss: 4.8700 - val_acc: 0.0108
Epoch 2/20
6660/6680 [============================>.] - ETA: 0s - loss: 4.8735 - acc: 0.0126Epoch 00001: val_loss improved from 4.87000 to 4.85923, saving model to saved_models/weights.best.from_scratch.hdf5
6680/6680 [==============================] - 135s - loss: 4.8735 - acc: 0.0126 - val_loss: 4.8592 - val_acc: 0.0156
Epoch 3/20
6660/6680 [============================>.] - ETA: 0s - loss: 4.8279 - acc: 0.0149Epoch 00002: val_loss improved from 4.85923 to 4.81452, saving model to saved_models/weights.best.from_scratch.hdf5
6680/6680 [==============================] - 135s - loss: 4.8282 - acc: 0.0148 - val_loss: 4.8145 - val_acc: 0.0192
Epoch 4/20
6660/6680 [============================>.] - ETA: 0s - loss: 4.7658 - acc: 0.0210Epoch 00003: val_loss improved from 4.81452 to 4.74105, saving model to saved_models/weights.best.from_scratch.hdf5
6680/6680 [==============================] - 134s - loss: 4.7658 - acc: 0.0211 - val_loss: 4.7411 - val_acc: 0.0228
Epoch 5/20
6660/6680 [============================>.] - ETA: 0s - loss: 4.7227 - acc: 0.0240Epoch 00004: val_loss did not improve
6680/6680 [==============================] - 135s - loss: 4.7233 - acc: 0.0240 - val_loss: 4.7478 - val_acc: 0.0263
Epoch 6/20
6660/6680 [============================>.] - ETA: 0s - loss: 4.6693 - acc: 0.0287Epoch 00005: val_loss did not improve
6680/6680 [==============================] - 134s - loss: 4.6686 - acc: 0.0287 - val_loss: 4.7523 - val_acc: 0.0299
Epoch 7/20
6660/6680 [============================>.] - ETA: 0s - loss: 4.6059 - acc: 0.0366Epoch 00006: val_loss improved from 4.74105 to 4.58340, saving model to saved_models/weights.best.from_scratch.hdf5
6680/6680 [==============================] - 135s - loss: 4.6058 - acc: 0.0365 - val_loss: 4.5834 - val_acc: 0.0383
Epoch 8/20
6660/6680 [============================>.] - ETA: 0s - loss: 4.5091 - acc: 0.0444Epoch 00007: val_loss improved from 4.58340 to 4.51508, saving model to saved_models/weights.best.from_scratch.hdf5
6680/6680 [==============================] - 134s - loss: 4.5097 - acc: 0.0443 - val_loss: 4.5151 - val_acc: 0.0443
Epoch 9/20
6660/6680 [============================>.] - ETA: 0s - loss: 4.4081 - acc: 0.0544Epoch 00008: val_loss improved from 4.51508 to 4.41531, saving model to saved_models/weights.best.from_scratch.hdf5
6680/6680 [==============================] - 134s - loss: 4.4089 - acc: 0.0545 - val_loss: 4.4153 - val_acc: 0.0623
Epoch 10/20
6660/6680 [============================>.] - ETA: 0s - loss: 4.3010 - acc: 0.0628Epoch 00009: val_loss improved from 4.41531 to 4.33327, saving model to saved_models/weights.best.from_scratch.hdf5
6680/6680 [==============================] - 140s - loss: 4.2994 - acc: 0.0630 - val_loss: 4.3333 - val_acc: 0.0635
Epoch 11/20
6660/6680 [============================>.] - ETA: 0s - loss: 4.2259 - acc: 0.0674Epoch 00010: val_loss improved from 4.33327 to 4.26774, saving model to saved_models/weights.best.from_scratch.hdf5
6680/6680 [==============================] - 133s - loss: 4.2256 - acc: 0.0675 - val_loss: 4.2677 - val_acc: 0.0790
Epoch 12/20
6660/6680 [============================>.] - ETA: 0s - loss: 4.1494 - acc: 0.0821Epoch 00011: val_loss did not improve
6680/6680 [==============================] - 133s - loss: 4.1494 - acc: 0.0822 - val_loss: 4.2910 - val_acc: 0.0790
Epoch 13/20
6660/6680 [============================>.] - ETA: 0s - loss: 4.0790 - acc: 0.0860Epoch 00012: val_loss improved from 4.26774 to 4.15617, saving model to saved_models/weights.best.from_scratch.hdf5
6680/6680 [==============================] - 133s - loss: 4.0779 - acc: 0.0865 - val_loss: 4.1562 - val_acc: 0.0862
Epoch 14/20
6660/6680 [============================>.] - ETA: 0s - loss: 4.0090 - acc: 0.0940Epoch 00013: val_loss improved from 4.15617 to 4.11593, saving model to saved_models/weights.best.from_scratch.hdf5
6680/6680 [==============================] - 133s - loss: 4.0103 - acc: 0.0937 - val_loss: 4.1159 - val_acc: 0.1042
Epoch 15/20
6660/6680 [============================>.] - ETA: 0s - loss: 3.9454 - acc: 0.1051Epoch 00014: val_loss improved from 4.11593 to 4.09969, saving model to saved_models/weights.best.from_scratch.hdf5
6680/6680 [==============================] - 133s - loss: 3.9452 - acc: 0.1051 - val_loss: 4.0997 - val_acc: 0.0862
Epoch 16/20
6660/6680 [============================>.] - ETA: 0s - loss: 3.9001 - acc: 0.1125Epoch 00015: val_loss did not improve
6680/6680 [==============================] - 133s - loss: 3.9001 - acc: 0.1124 - val_loss: 4.4196 - val_acc: 0.0814
Epoch 17/20
6660/6680 [============================>.] - ETA: 0s - loss: 3.8292 - acc: 0.1242Epoch 00016: val_loss improved from 4.09969 to 4.05390, saving model to saved_models/weights.best.from_scratch.hdf5
6680/6680 [==============================] - 133s - loss: 3.8290 - acc: 0.1241 - val_loss: 4.0539 - val_acc: 0.1078
Epoch 18/20
6660/6680 [============================>.] - ETA: 0s - loss: 3.7799 - acc: 0.1326Epoch 00017: val_loss improved from 4.05390 to 3.96395, saving model to saved_models/weights.best.from_scratch.hdf5
6680/6680 [==============================] - 133s - loss: 3.7786 - acc: 0.1325 - val_loss: 3.9639 - val_acc: 0.1246
Epoch 19/20
6660/6680 [============================>.] - ETA: 0s - loss: 3.7254 - acc: 0.1416Epoch 00018: val_loss did not improve
6680/6680 [==============================] - 137s - loss: 3.7255 - acc: 0.1416 - val_loss: 4.0200 - val_acc: 0.1066
Epoch 20/20
6660/6680 [============================>.] - ETA: 0s - loss: 3.6751 - acc: 0.1426Epoch 00019: val_loss improved from 3.96395 to 3.95601, saving model to saved_models/weights.best.from_scratch.hdf5
6680/6680 [==============================] - 138s - loss: 3.6747 - acc: 0.1425 - val_loss: 3.9560 - val_acc: 0.1281





